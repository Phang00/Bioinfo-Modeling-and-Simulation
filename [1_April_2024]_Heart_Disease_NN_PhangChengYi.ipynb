{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1q_qKIV2t2u"
      },
      "source": [
        "#Import all library needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "#confusion matrix visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Link notebook with google drive and access data from your personal Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "### 2.Set the data path for dataset and model location (ex: model_loc = \"/content/gdrive/My Drive/Dataset/\")\n",
        "dataset_dir = \"/content/gdrive/My Drive/ColabNotebooks/\"\n",
        "model_loc = \"/content/gdrive/My Drive/ColabNotebooks/\"\n",
        "\n",
        "print(os.listdir(dataset_dir))\n",
        "data = pd.read_csv(dataset_dir+'heart.csv')"
      ],
      "metadata": {
        "id": "WazdlOZefP88",
        "outputId": "91f0bb2e-34de-4620-9e5f-c24f384dce0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['Entrez_inclassexe.ipynb', 'Entrez_inclassexe2.ipynb', 'Task2_PhangChengYi_GohYitian.ipynb', 'Task1_PhangChengYi_GohYitian.ipynb', 'In Group Activity 1.ipynb', 'PSM1_v1.ipynb', 'penguin_size.ipynb', 'penguin_lter.ipynb', 'PSM1_v2.ipynb', 'PSM1_v4.ipynb', 'PSM1_v3.ipynb', 'PSM2_v1.ipynb', 'PSM2_v3_single word.ipynb', 'PSM2_v2_preprocessed_keyword.ipynb', 'heart.csv', 'Untitled0.ipynb', '[1_April_2024]_Heart_Disease_NN_PhangChengYi.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZADep6q2t3D"
      },
      "source": [
        "### 3. Insert Exploratory data analysis (EDA) steps to analyze and investigate datasets."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KEIfR5Rwhu1F",
        "outputId": "6bd75e53-907f-4000-b211-66854fcc6936"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51dcbba3-cc02-40cd-aa06-de020577f5a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51dcbba3-cc02-40cd-aa06-de020577f5a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51dcbba3-cc02-40cd-aa06-de020577f5a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51dcbba3-cc02-40cd-aa06-de020577f5a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff404258-9331-426d-a92e-2e7b97d33335\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff404258-9331-426d-a92e-2e7b97d33335')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff404258-9331-426d-a92e-2e7b97d33335 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          46,\n          66,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          104,\n          123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          277,\n          169\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          159,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1610750220686348,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          1.9,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5EQnTmOh1FG",
        "outputId": "70d121b8-13d0-4a06-b47f-d9778ef99a2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out summary of statistics of numeric columns\n",
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "B_sOLwlUjKbM",
        "outputId": "97bbdef1-7248-40f5-8e03-0f48db92de38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              age         sex          cp    trestbps        chol         fbs  \\\n",
              "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
              "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
              "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
              "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
              "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
              "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
              "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
              "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
              "\n",
              "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
              "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
              "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
              "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
              "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
              "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
              "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
              "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
              "\n",
              "             thal      target  \n",
              "count  303.000000  303.000000  \n",
              "mean     2.313531    0.544554  \n",
              "std      0.612277    0.498835  \n",
              "min      0.000000    0.000000  \n",
              "25%      2.000000    0.000000  \n",
              "50%      2.000000    1.000000  \n",
              "75%      3.000000    1.000000  \n",
              "max      3.000000    1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67be5a65-5705-4203-ba19-41926f3b2e99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>54.366337</td>\n",
              "      <td>0.683168</td>\n",
              "      <td>0.966997</td>\n",
              "      <td>131.623762</td>\n",
              "      <td>246.264026</td>\n",
              "      <td>0.148515</td>\n",
              "      <td>0.528053</td>\n",
              "      <td>149.646865</td>\n",
              "      <td>0.326733</td>\n",
              "      <td>1.039604</td>\n",
              "      <td>1.399340</td>\n",
              "      <td>0.729373</td>\n",
              "      <td>2.313531</td>\n",
              "      <td>0.544554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.082101</td>\n",
              "      <td>0.466011</td>\n",
              "      <td>1.032052</td>\n",
              "      <td>17.538143</td>\n",
              "      <td>51.830751</td>\n",
              "      <td>0.356198</td>\n",
              "      <td>0.525860</td>\n",
              "      <td>22.905161</td>\n",
              "      <td>0.469794</td>\n",
              "      <td>1.161075</td>\n",
              "      <td>0.616226</td>\n",
              "      <td>1.022606</td>\n",
              "      <td>0.612277</td>\n",
              "      <td>0.498835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>211.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>274.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>564.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67be5a65-5705-4203-ba19-41926f3b2e99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67be5a65-5705-4203-ba19-41926f3b2e99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67be5a65-5705-4203-ba19-41926f3b2e99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2193ad3-bb25-41a1-bedf-f5decd7461ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2193ad3-bb25-41a1-bedf-f5decd7461ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2193ad3-bb25-41a1-bedf-f5decd7461ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 92.63263171018461,\n        \"min\": 9.082100989837857,\n        \"max\": 303.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          54.366336633663366,\n          55.0,\n          303.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.91793021099774,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6831683168316832,\n          1.0,\n          0.46601082333962385\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.72725528212327,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          303.0,\n          0.966996699669967,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 82.65195263865039,\n        \"min\": 17.5381428135171,\n        \"max\": 303.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          131.62376237623764,\n          130.0,\n          303.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 150.35806568851743,\n        \"min\": 51.83075098793003,\n        \"max\": 564.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          246.26402640264027,\n          240.0,\n          303.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107.0512286741478,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1485148514851485,\n          1.0,\n          0.35619787492797644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.8733588009897,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          0.528052805280528,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.70384393886218,\n        \"min\": 22.905161114914094,\n        \"max\": 303.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          149.64686468646866,\n          153.0,\n          303.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.9862394088184,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.32673267326732675,\n          1.0,\n          0.4697944645223165\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.59952466080658,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          303.0,\n          1.0396039603960396,\n          1.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.72394469173834,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          1.3993399339933994,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.79372080487734,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          0.7293729372937293,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.47909774814387,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          2.3135313531353137,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.92326354929804,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5445544554455446,\n          1.0,\n          0.4988347841643913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data types of each column\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDTOPpkBkowF",
        "outputId": "a8715635-ce5e-41c5-96aa-c74ce05106ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqScBz8kzcC",
        "outputId": "5b667c7c-7232-4749-e013-5da8a4251b33"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trestbps    0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalach     0\n",
              "exang       0\n",
              "oldpeak     0\n",
              "slope       0\n",
              "ca          0\n",
              "thal        0\n",
              "target      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ylkru32t27"
      },
      "source": [
        "### 4. What is the purpose of the code that sets a list of categorical variables\n",
        "### in a dataset and then casts those variables to the object data type using the astype() function?\n",
        "###  The purpose is to convert specific columns in the Dataframe 'data' to the data type 'object' for each item in the list 'categorialList',\n",
        "###  to ensure that these variables are treated as categorical variables for the following analysis or modeling process.\n",
        "\n",
        "catagorialList = ['sex','cp','fbs','restecg','exang','ca','thal']\n",
        "for item in catagorialList:\n",
        "    data[item] = data[item].astype('object') #casting to object"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbqP4z32t3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d84d9c50-aa3f-4b72-a4fc-22f8cc0deb9a"
      },
      "source": [
        " ### 5. Create more data by categorical variable into indicator variables using 'get_dummies' function\n",
        "data = pd.get_dummies(data, drop_first=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-80e670da85f6>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-10-80e670da85f6>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-10-80e670da85f6>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-10-80e670da85f6>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-10-80e670da85f6>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-10-80e670da85f6>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-10-80e670da85f6>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlOEgqg2t3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e04db43-1c0b-49a6-e68b-f28c7a0d735c"
      },
      "source": [
        "### 6. Explain line 3,4 and 5 and print the shape of x and y\n",
        "y = data['target'].values #take the target value\n",
        "y = y.reshape(y.shape[0],1) #reshape y array into 1 dimension\n",
        "x = data.drop(['target'],axis=1) #drop 'target' in x data\n",
        "y.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3lUsbVZnP8h",
        "outputId": "954f2f1d-bea1-445b-f73d-85971256239e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCt-WPckusoh",
        "outputId": "a60c3e87-3790-438d-b863-9d07fd76156c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEGdOBJu2t3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19f1526-ae2d-465c-afba-e1fbfbe0df3a"
      },
      "source": [
        "### 7. Create a simple dataset and demonstrate the normalization code on the simple dataset\n",
        "data = pd.DataFrame({'A': [10,20,30], 'B': [100,200,300], 'C': [1000,2000,3000]})\n",
        "print('Original dataset:')\n",
        "print(data)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset:\n",
            "    A    B     C\n",
            "0  10  100  1000\n",
            "1  20  200  2000\n",
            "2  30  300  3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 8. Describe the heart dataset after implementing the min max normalization\n",
        "#Normalize data (range 0 - 1)\n",
        "minx = np.min(x)\n",
        "maxx = np.max(x)\n",
        "x = (x - minx) / (maxx - minx)\n",
        "x.head()"
      ],
      "metadata": {
        "id": "asoFBQaumuKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "3337584d-86b0-476d-c4f1-9961591c2ddf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  trestbps      chol   thalach   oldpeak  slope  sex_1  cp_1  cp_2  \\\n",
              "0  0.708333  0.481132  0.244292  0.603053  0.370968    0.0    1.0   0.0   0.0   \n",
              "1  0.166667  0.339623  0.283105  0.885496  0.564516    0.0    1.0   0.0   1.0   \n",
              "2  0.250000  0.339623  0.178082  0.770992  0.225806    1.0    0.0   1.0   0.0   \n",
              "3  0.562500  0.245283  0.251142  0.816794  0.129032    1.0    1.0   1.0   0.0   \n",
              "4  0.583333  0.245283  0.520548  0.702290  0.096774    1.0    0.0   0.0   0.0   \n",
              "\n",
              "   cp_3  ...  restecg_1  restecg_2  exang_1  ca_1  ca_2  ca_3  ca_4  thal_1  \\\n",
              "0   1.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     1.0   \n",
              "1   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "2   0.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "3   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "4   0.0  ...        1.0        0.0      1.0   0.0   0.0   0.0   0.0     0.0   \n",
              "\n",
              "   thal_2  thal_3  \n",
              "0     0.0     0.0  \n",
              "1     1.0     0.0  \n",
              "2     1.0     0.0  \n",
              "3     1.0     0.0  \n",
              "4     1.0     0.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28196b6e-fdc4-4f16-af11-fbe67af3da77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>...</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.244292</td>\n",
              "      <td>0.603053</td>\n",
              "      <td>0.370968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.283105</td>\n",
              "      <td>0.885496</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.251142</td>\n",
              "      <td>0.816794</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.702290</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28196b6e-fdc4-4f16-af11-fbe67af3da77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28196b6e-fdc4-4f16-af11-fbe67af3da77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28196b6e-fdc4-4f16-af11-fbe67af3da77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9af6638e-003b-44d1-a598-3e1427231bbd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9af6638e-003b-44d1-a598-3e1427231bbd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9af6638e-003b-44d1-a598-3e1427231bbd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvykedw82t3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f0054a-535c-4708-df90-49ce3f6c1753"
      },
      "source": [
        "### 9. Modify the code to split the dataset into train and test (train 70%, val 20% and test 10%).\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "# # re-create train and validation set\n",
        "# x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# train 70%, validation 20%, test 10%\n",
        "# Splitting the data into train and test sets (70% train, 30% test)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "# Splitting the remaining training data into train and validation sets (80% train, 20% validation)\n",
        "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.20, random_state=42)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(169, 21)\n",
            "(43, 21)\n",
            "(91, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBAU_MDlqnfo",
        "outputId": "d8101f1d-3417-4c6d-c1f9-82712a74ed8c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pwz5A_j2t30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b4691b-d4fc-4178-c78d-cf1f5278ad37"
      },
      "source": [
        "### 10. What is the purpose of each layer in the neural network created using the Sequential() function with 64, 32, and 1 neurons,\n",
        "### respectively, and softmax and sigmoid activation functions?\n",
        "###     In this network, the input layer is assumed to be present implicitly. There are two hidden layers with 64 and 32 neurons respectively. The output layer consists of a single neuron.\n",
        "###     Softmax activation function is used in the hidden layers for classification tasks to convert the raw output of each neuron into a probability distribution over multiple classes,\n",
        "###     ensuring that the output values are between 0 and 1 and sum up to 1.\n",
        "###     Sigmoid activation function is used in the output layer for binary classification tasks or regression tasks where the output needs to be constrained between 0 and 1.\n",
        "###     It squashes the output of the neuron to the range [0, 1], interpreting it as a probability of belonging to the positive class in binary classification tasks.\n",
        "\n",
        "model = Sequential() #Allow us to create model layer by layer\n",
        "model.add(Dense(64, input_dim=21, activation='softmax')) #Softmax turn number data into probabilities which sum to 1\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.add(Dense(1, activation='sigmoid')) # produce probability value (number between 0 or 1)\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                1408      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3521 (13.75 KB)\n",
            "Trainable params: 3521 (13.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0pM4z_OQfNi"
      },
      "source": [
        "### 11. This code compiles a neural network model with a mean squared error loss function, the Adam optimizer with a learning rate of 0.01,\n",
        "### and accuracy as a performance metric. What does each of these components mean, and how do they affect the model training and performance?\n",
        "###     - The mean squared error (mse) loss function measures how well the model's predictions match the actual target values during training.\n",
        "###       It calculates the average of the squared differences between the predicted and actual values.\n",
        "###     - Adam optimizer an optimization algorithm that combines ideas from RMSprop and momentum methods.\n",
        "###       It is used for updating the model's weights based on the calculated gradients of the loss function.\n",
        "###       Learning rate is the step size taken during optimization process. In this case, the learning rate is 0.01.\n",
        "###     - Metrics are used to evaluate the performance of the model during training and testing.\n",
        "###       Accuracy is a metric that used to calculates the proportion of correct predictions among the total number of predictions.\n",
        "###     - The choice of loss function affects how the model learns from its mistakes during training. MSE loss, in this case, encourages the model to minimize\n",
        "###       the squared differences between predictions and actual values. The optimizer determines how the model's weights are updated based on the loss and gradients.\n",
        "###       Adam optimizer, with its adaptive learning rate and momentum, helps in efficient and effective weight updates, potentially leading to faster convergence and better generalization.\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxSIBnZ2t36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d529ac3c-7cc3-4350-8f25-07b252d37bed"
      },
      "source": [
        "# start the model training\n",
        "output = []\n",
        "early = EarlyStopping(monitor='val_acc', patience=400, mode='auto')\n",
        "checkpoint = ModelCheckpoint(model_loc+\"heart_disease_best_model.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.01, patience=100, verbose=1, mode='auto', min_lr=0.001)\n",
        "callbacks_list = [early]\n",
        "\n",
        "output = model.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=1000, batch_size=16, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "11/11 [==============================] - 3s 54ms/step - loss: 0.2505 - acc: 0.4852 - val_loss: 0.2502 - val_acc: 0.4884\n",
            "Epoch 2/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2477 - acc: 0.5562 - val_loss: 0.2507 - val_acc: 0.4884\n",
            "Epoch 3/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2459 - acc: 0.5562 - val_loss: 0.2502 - val_acc: 0.4884\n",
            "Epoch 4/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2423 - acc: 0.5562 - val_loss: 0.2458 - val_acc: 0.4884\n",
            "Epoch 5/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2367 - acc: 0.5562 - val_loss: 0.2397 - val_acc: 0.4884\n",
            "Epoch 6/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2283 - acc: 0.5562 - val_loss: 0.2281 - val_acc: 0.4884\n",
            "Epoch 7/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2156 - acc: 0.6686 - val_loss: 0.2115 - val_acc: 0.8140\n",
            "Epoch 8/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2010 - acc: 0.8462 - val_loss: 0.1942 - val_acc: 0.8605\n",
            "Epoch 9/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1850 - acc: 0.8462 - val_loss: 0.1784 - val_acc: 0.8605\n",
            "Epoch 10/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1693 - acc: 0.8402 - val_loss: 0.1638 - val_acc: 0.8605\n",
            "Epoch 11/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.1553 - acc: 0.8462 - val_loss: 0.1534 - val_acc: 0.8605\n",
            "Epoch 12/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1441 - acc: 0.8580 - val_loss: 0.1449 - val_acc: 0.8605\n",
            "Epoch 13/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1346 - acc: 0.8521 - val_loss: 0.1399 - val_acc: 0.8605\n",
            "Epoch 14/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.1273 - acc: 0.8521 - val_loss: 0.1368 - val_acc: 0.8605\n",
            "Epoch 15/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1200 - acc: 0.8580 - val_loss: 0.1361 - val_acc: 0.8605\n",
            "Epoch 16/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1151 - acc: 0.8580 - val_loss: 0.1385 - val_acc: 0.8372\n",
            "Epoch 17/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1101 - acc: 0.8639 - val_loss: 0.1391 - val_acc: 0.8372\n",
            "Epoch 18/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1065 - acc: 0.8757 - val_loss: 0.1397 - val_acc: 0.8372\n",
            "Epoch 19/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1056 - acc: 0.8817 - val_loss: 0.1388 - val_acc: 0.8372\n",
            "Epoch 20/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1018 - acc: 0.8757 - val_loss: 0.1400 - val_acc: 0.8372\n",
            "Epoch 21/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0988 - acc: 0.8876 - val_loss: 0.1429 - val_acc: 0.8140\n",
            "Epoch 22/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0972 - acc: 0.8876 - val_loss: 0.1413 - val_acc: 0.8372\n",
            "Epoch 23/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0947 - acc: 0.8876 - val_loss: 0.1437 - val_acc: 0.7907\n",
            "Epoch 24/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0918 - acc: 0.8876 - val_loss: 0.1436 - val_acc: 0.7907\n",
            "Epoch 25/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0942 - acc: 0.8876 - val_loss: 0.1412 - val_acc: 0.8372\n",
            "Epoch 26/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0892 - acc: 0.8935 - val_loss: 0.1524 - val_acc: 0.7674\n",
            "Epoch 27/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0859 - acc: 0.8994 - val_loss: 0.1466 - val_acc: 0.8140\n",
            "Epoch 28/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0840 - acc: 0.9053 - val_loss: 0.1454 - val_acc: 0.8372\n",
            "Epoch 29/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0812 - acc: 0.9053 - val_loss: 0.1481 - val_acc: 0.8140\n",
            "Epoch 30/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0801 - acc: 0.9053 - val_loss: 0.1519 - val_acc: 0.8140\n",
            "Epoch 31/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0763 - acc: 0.9172 - val_loss: 0.1560 - val_acc: 0.7907\n",
            "Epoch 32/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0732 - acc: 0.9112 - val_loss: 0.1544 - val_acc: 0.8140\n",
            "Epoch 33/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0697 - acc: 0.9231 - val_loss: 0.1566 - val_acc: 0.7907\n",
            "Epoch 34/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0676 - acc: 0.9290 - val_loss: 0.1548 - val_acc: 0.7907\n",
            "Epoch 35/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0686 - acc: 0.9172 - val_loss: 0.1551 - val_acc: 0.8140\n",
            "Epoch 36/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0644 - acc: 0.9290 - val_loss: 0.1595 - val_acc: 0.7907\n",
            "Epoch 37/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0650 - acc: 0.9349 - val_loss: 0.1621 - val_acc: 0.7907\n",
            "Epoch 38/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0623 - acc: 0.9349 - val_loss: 0.1628 - val_acc: 0.7907\n",
            "Epoch 39/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0622 - acc: 0.9290 - val_loss: 0.1609 - val_acc: 0.7907\n",
            "Epoch 40/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0617 - acc: 0.9349 - val_loss: 0.1676 - val_acc: 0.7907\n",
            "Epoch 41/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0604 - acc: 0.9408 - val_loss: 0.1610 - val_acc: 0.7907\n",
            "Epoch 42/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0575 - acc: 0.9467 - val_loss: 0.1681 - val_acc: 0.7907\n",
            "Epoch 43/1000\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0558 - acc: 0.9467 - val_loss: 0.1649 - val_acc: 0.7907\n",
            "Epoch 44/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0567 - acc: 0.9408 - val_loss: 0.1669 - val_acc: 0.7907\n",
            "Epoch 45/1000\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0554 - acc: 0.9408 - val_loss: 0.1709 - val_acc: 0.7907\n",
            "Epoch 46/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0525 - acc: 0.9467 - val_loss: 0.1617 - val_acc: 0.8372\n",
            "Epoch 47/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0490 - acc: 0.9586 - val_loss: 0.1636 - val_acc: 0.8140\n",
            "Epoch 48/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0474 - acc: 0.9527 - val_loss: 0.1641 - val_acc: 0.8140\n",
            "Epoch 49/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0436 - acc: 0.9586 - val_loss: 0.1691 - val_acc: 0.8140\n",
            "Epoch 50/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0444 - acc: 0.9527 - val_loss: 0.1698 - val_acc: 0.7907\n",
            "Epoch 51/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0439 - acc: 0.9586 - val_loss: 0.1703 - val_acc: 0.8140\n",
            "Epoch 52/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0408 - acc: 0.9645 - val_loss: 0.1660 - val_acc: 0.8140\n",
            "Epoch 53/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0416 - acc: 0.9586 - val_loss: 0.1763 - val_acc: 0.7907\n",
            "Epoch 54/1000\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.0409 - acc: 0.9527 - val_loss: 0.1749 - val_acc: 0.7907\n",
            "Epoch 55/1000\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.0404 - acc: 0.9586 - val_loss: 0.1734 - val_acc: 0.7907\n",
            "Epoch 56/1000\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.0403 - acc: 0.9586 - val_loss: 0.1768 - val_acc: 0.7907\n",
            "Epoch 57/1000\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0393 - acc: 0.9586 - val_loss: 0.1782 - val_acc: 0.7907\n",
            "Epoch 58/1000\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.0396 - acc: 0.9586 - val_loss: 0.1786 - val_acc: 0.7907\n",
            "Epoch 59/1000\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0392 - acc: 0.9586 - val_loss: 0.1752 - val_acc: 0.7907\n",
            "Epoch 60/1000\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.0390 - acc: 0.9586 - val_loss: 0.1864 - val_acc: 0.7907\n",
            "Epoch 61/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0398 - acc: 0.9527 - val_loss: 0.1799 - val_acc: 0.7907\n",
            "Epoch 62/1000\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0386 - acc: 0.9586 - val_loss: 0.1854 - val_acc: 0.7674\n",
            "Epoch 63/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0386 - acc: 0.9586 - val_loss: 0.1766 - val_acc: 0.7907\n",
            "Epoch 64/1000\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.0384 - acc: 0.9586 - val_loss: 0.1787 - val_acc: 0.7907\n",
            "Epoch 65/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0378 - acc: 0.9645 - val_loss: 0.1852 - val_acc: 0.7907\n",
            "Epoch 66/1000\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.0390 - acc: 0.9586 - val_loss: 0.1819 - val_acc: 0.7907\n",
            "Epoch 67/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0401 - acc: 0.9586 - val_loss: 0.1797 - val_acc: 0.7907\n",
            "Epoch 68/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0379 - acc: 0.9645 - val_loss: 0.1919 - val_acc: 0.7674\n",
            "Epoch 69/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0385 - acc: 0.9586 - val_loss: 0.1832 - val_acc: 0.7907\n",
            "Epoch 70/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0377 - acc: 0.9586 - val_loss: 0.1837 - val_acc: 0.7907\n",
            "Epoch 71/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0373 - acc: 0.9645 - val_loss: 0.1848 - val_acc: 0.7907\n",
            "Epoch 72/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0373 - acc: 0.9645 - val_loss: 0.1825 - val_acc: 0.7907\n",
            "Epoch 73/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0372 - acc: 0.9645 - val_loss: 0.1889 - val_acc: 0.7907\n",
            "Epoch 74/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0374 - acc: 0.9586 - val_loss: 0.1824 - val_acc: 0.7907\n",
            "Epoch 75/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0376 - acc: 0.9645 - val_loss: 0.1840 - val_acc: 0.7907\n",
            "Epoch 76/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0385 - acc: 0.9586 - val_loss: 0.1814 - val_acc: 0.8140\n",
            "Epoch 77/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0364 - acc: 0.9645 - val_loss: 0.1900 - val_acc: 0.7907\n",
            "Epoch 78/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0370 - acc: 0.9645 - val_loss: 0.1898 - val_acc: 0.7907\n",
            "Epoch 79/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0419 - acc: 0.9527 - val_loss: 0.1803 - val_acc: 0.8140\n",
            "Epoch 80/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0358 - acc: 0.9586 - val_loss: 0.1984 - val_acc: 0.7674\n",
            "Epoch 81/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0372 - acc: 0.9645 - val_loss: 0.1869 - val_acc: 0.7907\n",
            "Epoch 82/1000\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.0343 - acc: 0.9645 - val_loss: 0.1819 - val_acc: 0.8140\n",
            "Epoch 83/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0330 - acc: 0.9704 - val_loss: 0.1861 - val_acc: 0.8140\n",
            "Epoch 84/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0324 - acc: 0.9704 - val_loss: 0.1867 - val_acc: 0.8140\n",
            "Epoch 85/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0322 - acc: 0.9704 - val_loss: 0.1899 - val_acc: 0.7907\n",
            "Epoch 86/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0323 - acc: 0.9704 - val_loss: 0.1911 - val_acc: 0.7674\n",
            "Epoch 87/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0324 - acc: 0.9645 - val_loss: 0.1955 - val_acc: 0.7674\n",
            "Epoch 88/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0317 - acc: 0.9704 - val_loss: 0.1866 - val_acc: 0.8140\n",
            "Epoch 89/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0315 - acc: 0.9704 - val_loss: 0.1904 - val_acc: 0.8140\n",
            "Epoch 90/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0314 - acc: 0.9704 - val_loss: 0.1898 - val_acc: 0.8140\n",
            "Epoch 91/1000\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0314 - acc: 0.9704 - val_loss: 0.1907 - val_acc: 0.7907\n",
            "Epoch 92/1000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0319 - acc: 0.9704 - val_loss: 0.1926 - val_acc: 0.7907\n",
            "Epoch 93/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0322 - acc: 0.9704 - val_loss: 0.1910 - val_acc: 0.7907\n",
            "Epoch 94/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0319 - acc: 0.9704 - val_loss: 0.1971 - val_acc: 0.7674\n",
            "Epoch 95/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0310 - acc: 0.9704 - val_loss: 0.1910 - val_acc: 0.8140\n",
            "Epoch 96/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0308 - acc: 0.9704 - val_loss: 0.1936 - val_acc: 0.7674\n",
            "Epoch 97/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0307 - acc: 0.9704 - val_loss: 0.1943 - val_acc: 0.7674\n",
            "Epoch 98/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0307 - acc: 0.9704 - val_loss: 0.1942 - val_acc: 0.7674\n",
            "Epoch 99/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0319 - acc: 0.9645 - val_loss: 0.1890 - val_acc: 0.7907\n",
            "Epoch 100/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0309 - acc: 0.9704 - val_loss: 0.2054 - val_acc: 0.7442\n",
            "Epoch 101/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0313 - acc: 0.9704 - val_loss: 0.1913 - val_acc: 0.7907\n",
            "Epoch 102/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0306 - acc: 0.9704 - val_loss: 0.2005 - val_acc: 0.7442\n",
            "Epoch 103/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0306 - acc: 0.9704 - val_loss: 0.1888 - val_acc: 0.7907\n",
            "Epoch 104/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0318 - acc: 0.9704 - val_loss: 0.1993 - val_acc: 0.7442\n",
            "Epoch 105/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0304 - acc: 0.9704 - val_loss: 0.2026 - val_acc: 0.7442\n",
            "Epoch 106/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0303 - acc: 0.9704 - val_loss: 0.1950 - val_acc: 0.7674\n",
            "Epoch 107/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0302 - acc: 0.9704 - val_loss: 0.1927 - val_acc: 0.7907\n",
            "Epoch 108/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.0302 - acc: 0.9704 - val_loss: 0.1975 - val_acc: 0.7442\n",
            "Epoch 109/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0301 - acc: 0.9704 - val_loss: 0.1964 - val_acc: 0.7674\n",
            "Epoch 110/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0300 - acc: 0.9704 - val_loss: 0.2010 - val_acc: 0.7442\n",
            "Epoch 111/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0302 - acc: 0.9704 - val_loss: 0.1972 - val_acc: 0.7442\n",
            "Epoch 112/1000\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0300 - acc: 0.9704 - val_loss: 0.1978 - val_acc: 0.7442\n",
            "Epoch 113/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0301 - acc: 0.9704 - val_loss: 0.2007 - val_acc: 0.7442\n",
            "Epoch 114/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0300 - acc: 0.9704 - val_loss: 0.2007 - val_acc: 0.7442\n",
            "Epoch 115/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0299 - acc: 0.9704 - val_loss: 0.1954 - val_acc: 0.7674\n",
            "Epoch 116/1000\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.0299 - acc: 0.9704 - val_loss: 0.2002 - val_acc: 0.7442\n",
            "Epoch 117/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.0298 - acc: 0.9704 - val_loss: 0.1984 - val_acc: 0.7442\n",
            "Epoch 118/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0299 - acc: 0.9704 - val_loss: 0.1969 - val_acc: 0.7442\n",
            "Epoch 119/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0298 - acc: 0.9704 - val_loss: 0.2003 - val_acc: 0.7442\n",
            "Epoch 120/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.0300 - acc: 0.9704 - val_loss: 0.2007 - val_acc: 0.7442\n",
            "Epoch 121/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0298 - acc: 0.9704 - val_loss: 0.1972 - val_acc: 0.7442\n",
            "Epoch 122/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0298 - acc: 0.9704 - val_loss: 0.2012 - val_acc: 0.7442\n",
            "Epoch 123/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0298 - acc: 0.9704 - val_loss: 0.1983 - val_acc: 0.7442\n",
            "Epoch 124/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.1985 - val_acc: 0.7442\n",
            "Epoch 125/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.2047 - val_acc: 0.7442\n",
            "Epoch 126/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.2051 - val_acc: 0.7442\n",
            "Epoch 127/1000\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.1998 - val_acc: 0.7442\n",
            "Epoch 128/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0296 - acc: 0.9704 - val_loss: 0.1959 - val_acc: 0.7442\n",
            "Epoch 129/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0296 - acc: 0.9704 - val_loss: 0.2018 - val_acc: 0.7442\n",
            "Epoch 130/1000\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.0296 - acc: 0.9704 - val_loss: 0.2021 - val_acc: 0.7442\n",
            "Epoch 131/1000\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.2025 - val_acc: 0.7442\n",
            "Epoch 132/1000\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.2103 - val_acc: 0.7442\n",
            "Epoch 133/1000\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0298 - acc: 0.9704 - val_loss: 0.1984 - val_acc: 0.7442\n",
            "Epoch 134/1000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.0306 - acc: 0.9704 - val_loss: 0.1956 - val_acc: 0.7442\n",
            "Epoch 135/1000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.0296 - acc: 0.9704 - val_loss: 0.2131 - val_acc: 0.7442\n",
            "Epoch 136/1000\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.1999 - val_acc: 0.7442\n",
            "Epoch 137/1000\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0295 - acc: 0.9704 - val_loss: 0.1958 - val_acc: 0.7442\n",
            "Epoch 138/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0296 - acc: 0.9704 - val_loss: 0.2028 - val_acc: 0.7442\n",
            "Epoch 139/1000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0295 - acc: 0.9704 - val_loss: 0.1992 - val_acc: 0.7442\n",
            "Epoch 140/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0295 - acc: 0.9704 - val_loss: 0.2011 - val_acc: 0.7442\n",
            "Epoch 141/1000\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.0296 - acc: 0.9704 - val_loss: 0.2079 - val_acc: 0.7442\n",
            "Epoch 142/1000\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.0298 - acc: 0.9704 - val_loss: 0.1968 - val_acc: 0.7442\n",
            "Epoch 143/1000\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.2082 - val_acc: 0.7442\n",
            "Epoch 144/1000\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.0295 - acc: 0.9704 - val_loss: 0.1988 - val_acc: 0.7442\n",
            "Epoch 145/1000\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0295 - acc: 0.9704 - val_loss: 0.1975 - val_acc: 0.7442\n",
            "Epoch 146/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2004 - val_acc: 0.7442\n",
            "Epoch 147/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2047 - val_acc: 0.7442\n",
            "Epoch 148/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2031 - val_acc: 0.7442\n",
            "Epoch 149/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2048 - val_acc: 0.7442\n",
            "Epoch 150/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2064 - val_acc: 0.7442\n",
            "Epoch 151/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2011 - val_acc: 0.7442\n",
            "Epoch 152/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2044 - val_acc: 0.7442\n",
            "Epoch 153/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2057 - val_acc: 0.7442\n",
            "Epoch 154/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2036 - val_acc: 0.7442\n",
            "Epoch 155/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2033 - val_acc: 0.7442\n",
            "Epoch 156/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2025 - val_acc: 0.7442\n",
            "Epoch 157/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2035 - val_acc: 0.7442\n",
            "Epoch 158/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2055 - val_acc: 0.7442\n",
            "Epoch 159/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.1991 - val_acc: 0.7442\n",
            "Epoch 160/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0294 - acc: 0.9704 - val_loss: 0.2066 - val_acc: 0.7442\n",
            "Epoch 161/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2022 - val_acc: 0.7442\n",
            "Epoch 162/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2016 - val_acc: 0.7442\n",
            "Epoch 163/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2036 - val_acc: 0.7442\n",
            "Epoch 164/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2017 - val_acc: 0.7442\n",
            "Epoch 165/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2039 - val_acc: 0.7442\n",
            "Epoch 166/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2036 - val_acc: 0.7442\n",
            "Epoch 167/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2039 - val_acc: 0.7442\n",
            "Epoch 168/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2016 - val_acc: 0.7442\n",
            "Epoch 169/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2052 - val_acc: 0.7442\n",
            "Epoch 170/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2021 - val_acc: 0.7442\n",
            "Epoch 171/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2041 - val_acc: 0.7442\n",
            "Epoch 172/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2049 - val_acc: 0.7442\n",
            "Epoch 173/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2021 - val_acc: 0.7442\n",
            "Epoch 174/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2015 - val_acc: 0.7442\n",
            "Epoch 175/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2043 - val_acc: 0.7442\n",
            "Epoch 176/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2041 - val_acc: 0.7442\n",
            "Epoch 177/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2030 - val_acc: 0.7442\n",
            "Epoch 178/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2058 - val_acc: 0.7442\n",
            "Epoch 179/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0293 - acc: 0.9704 - val_loss: 0.2069 - val_acc: 0.7442\n",
            "Epoch 180/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.1993 - val_acc: 0.7442\n",
            "Epoch 181/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2027 - val_acc: 0.7442\n",
            "Epoch 182/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2045 - val_acc: 0.7442\n",
            "Epoch 183/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2069 - val_acc: 0.7442\n",
            "Epoch 184/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2030 - val_acc: 0.7442\n",
            "Epoch 185/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2044 - val_acc: 0.7442\n",
            "Epoch 186/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2029 - val_acc: 0.7442\n",
            "Epoch 187/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2058 - val_acc: 0.7442\n",
            "Epoch 188/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2047 - val_acc: 0.7442\n",
            "Epoch 189/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2007 - val_acc: 0.7442\n",
            "Epoch 190/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2029 - val_acc: 0.7442\n",
            "Epoch 191/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2034 - val_acc: 0.7442\n",
            "Epoch 192/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2029 - val_acc: 0.7442\n",
            "Epoch 193/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2028 - val_acc: 0.7442\n",
            "Epoch 194/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2010 - val_acc: 0.7442\n",
            "Epoch 195/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2033 - val_acc: 0.7442\n",
            "Epoch 196/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2014 - val_acc: 0.7442\n",
            "Epoch 197/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2061 - val_acc: 0.7442\n",
            "Epoch 198/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.2001 - val_acc: 0.7442\n",
            "Epoch 199/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2008 - val_acc: 0.7442\n",
            "Epoch 200/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.2020 - val_acc: 0.7442\n",
            "Epoch 201/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0292 - acc: 0.9704 - val_loss: 0.1985 - val_acc: 0.7442\n",
            "Epoch 202/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.2015 - val_acc: 0.7442\n",
            "Epoch 203/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.2009 - val_acc: 0.7442\n",
            "Epoch 204/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.2005 - val_acc: 0.7442\n",
            "Epoch 205/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.2005 - val_acc: 0.7442\n",
            "Epoch 206/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1983 - val_acc: 0.7442\n",
            "Epoch 207/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.2002 - val_acc: 0.7442\n",
            "Epoch 208/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1984 - val_acc: 0.7442\n",
            "Epoch 209/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1988 - val_acc: 0.7442\n",
            "Epoch 210/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1982 - val_acc: 0.7442\n",
            "Epoch 211/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1938 - val_acc: 0.7442\n",
            "Epoch 212/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1981 - val_acc: 0.7442\n",
            "Epoch 213/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.2015 - val_acc: 0.7442\n",
            "Epoch 214/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1991 - val_acc: 0.7442\n",
            "Epoch 215/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1930 - val_acc: 0.7442\n",
            "Epoch 216/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1998 - val_acc: 0.7442\n",
            "Epoch 217/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0291 - acc: 0.9704 - val_loss: 0.1978 - val_acc: 0.7442\n",
            "Epoch 218/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0290 - acc: 0.9704 - val_loss: 0.1989 - val_acc: 0.7442\n",
            "Epoch 219/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0290 - acc: 0.9704 - val_loss: 0.1936 - val_acc: 0.7442\n",
            "Epoch 220/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0290 - acc: 0.9704 - val_loss: 0.1897 - val_acc: 0.7907\n",
            "Epoch 221/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0288 - acc: 0.9704 - val_loss: 0.1926 - val_acc: 0.7674\n",
            "Epoch 222/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0297 - acc: 0.9704 - val_loss: 0.2006 - val_acc: 0.7674\n",
            "Epoch 223/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0278 - acc: 0.9704 - val_loss: 0.2018 - val_acc: 0.7674\n",
            "Epoch 224/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0287 - acc: 0.9704 - val_loss: 0.1921 - val_acc: 0.7907\n",
            "Epoch 225/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0241 - acc: 0.9763 - val_loss: 0.2388 - val_acc: 0.7442\n",
            "Epoch 226/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0300 - acc: 0.9645 - val_loss: 0.1926 - val_acc: 0.7907\n",
            "Epoch 227/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0243 - acc: 0.9763 - val_loss: 0.2232 - val_acc: 0.7442\n",
            "Epoch 228/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0304 - acc: 0.9645 - val_loss: 0.2066 - val_acc: 0.7442\n",
            "Epoch 229/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0341 - acc: 0.9527 - val_loss: 0.1930 - val_acc: 0.7907\n",
            "Epoch 230/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0243 - acc: 0.9763 - val_loss: 0.2159 - val_acc: 0.7442\n",
            "Epoch 231/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0279 - acc: 0.9704 - val_loss: 0.2152 - val_acc: 0.7674\n",
            "Epoch 232/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0244 - acc: 0.9763 - val_loss: 0.2191 - val_acc: 0.7442\n",
            "Epoch 233/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.2068 - val_acc: 0.7442\n",
            "Epoch 234/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0237 - acc: 0.9763 - val_loss: 0.2072 - val_acc: 0.7674\n",
            "Epoch 235/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.2055 - val_acc: 0.7907\n",
            "Epoch 236/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.2068 - val_acc: 0.7442\n",
            "Epoch 237/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0234 - acc: 0.9763 - val_loss: 0.2070 - val_acc: 0.7674\n",
            "Epoch 238/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2066 - val_acc: 0.7674\n",
            "Epoch 239/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2063 - val_acc: 0.7674\n",
            "Epoch 240/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2063 - val_acc: 0.7674\n",
            "Epoch 241/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2065 - val_acc: 0.7674\n",
            "Epoch 242/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2067 - val_acc: 0.7674\n",
            "Epoch 243/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2064 - val_acc: 0.7674\n",
            "Epoch 244/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2067 - val_acc: 0.7674\n",
            "Epoch 245/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2062 - val_acc: 0.7674\n",
            "Epoch 246/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2063 - val_acc: 0.7674\n",
            "Epoch 247/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2062 - val_acc: 0.7674\n",
            "Epoch 248/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2058 - val_acc: 0.7674\n",
            "Epoch 249/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2056 - val_acc: 0.7674\n",
            "Epoch 250/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2057 - val_acc: 0.7674\n",
            "Epoch 251/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2055 - val_acc: 0.7674\n",
            "Epoch 252/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2056 - val_acc: 0.7674\n",
            "Epoch 253/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2053 - val_acc: 0.7674\n",
            "Epoch 254/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2053 - val_acc: 0.7674\n",
            "Epoch 255/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2052 - val_acc: 0.7674\n",
            "Epoch 256/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2052 - val_acc: 0.7674\n",
            "Epoch 257/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2049 - val_acc: 0.7674\n",
            "Epoch 258/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 259/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 260/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 261/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 262/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 263/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 264/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2048 - val_acc: 0.7674\n",
            "Epoch 265/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 266/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 267/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2048 - val_acc: 0.7674\n",
            "Epoch 268/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 269/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2051 - val_acc: 0.7674\n",
            "Epoch 270/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2051 - val_acc: 0.7674\n",
            "Epoch 271/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 272/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 273/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 274/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 275/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 276/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2048 - val_acc: 0.7674\n",
            "Epoch 277/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 278/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 279/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2043 - val_acc: 0.7674\n",
            "Epoch 280/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 281/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 282/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 283/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 284/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2044 - val_acc: 0.7674\n",
            "Epoch 285/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2044 - val_acc: 0.7674\n",
            "Epoch 286/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2042 - val_acc: 0.7674\n",
            "Epoch 287/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 288/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2042 - val_acc: 0.7674\n",
            "Epoch 289/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2042 - val_acc: 0.7674\n",
            "Epoch 290/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2042 - val_acc: 0.7674\n",
            "Epoch 291/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2043 - val_acc: 0.7674\n",
            "Epoch 292/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2044 - val_acc: 0.7674\n",
            "Epoch 293/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 294/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 295/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2044 - val_acc: 0.7674\n",
            "Epoch 296/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 297/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2040 - val_acc: 0.7674\n",
            "Epoch 298/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2044 - val_acc: 0.7674\n",
            "Epoch 299/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 300/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 301/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2039 - val_acc: 0.7674\n",
            "Epoch 302/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2043 - val_acc: 0.7674\n",
            "Epoch 303/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2042 - val_acc: 0.7674\n",
            "Epoch 304/1000\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2042 - val_acc: 0.7674\n",
            "Epoch 305/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 306/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2040 - val_acc: 0.7674\n",
            "Epoch 307/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2039 - val_acc: 0.7674\n",
            "Epoch 308/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 309/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 310/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2037 - val_acc: 0.7674\n",
            "Epoch 311/1000\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2034 - val_acc: 0.7674\n",
            "Epoch 312/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2036 - val_acc: 0.7674\n",
            "Epoch 313/1000\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 314/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 315/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2037 - val_acc: 0.7674\n",
            "Epoch 316/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2040 - val_acc: 0.7674\n",
            "Epoch 317/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2039 - val_acc: 0.7674\n",
            "Epoch 318/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2036 - val_acc: 0.7674\n",
            "Epoch 319/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2036 - val_acc: 0.7674\n",
            "Epoch 320/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2034 - val_acc: 0.7674\n",
            "Epoch 321/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 322/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 323/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2033 - val_acc: 0.7674\n",
            "Epoch 324/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2029 - val_acc: 0.7674\n",
            "Epoch 325/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2043 - val_acc: 0.7674\n",
            "Epoch 326/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2036 - val_acc: 0.7674\n",
            "Epoch 327/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2038 - val_acc: 0.7674\n",
            "Epoch 328/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2034 - val_acc: 0.7674\n",
            "Epoch 329/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2031 - val_acc: 0.7674\n",
            "Epoch 330/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2030 - val_acc: 0.7674\n",
            "Epoch 331/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2030 - val_acc: 0.7674\n",
            "Epoch 332/1000\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2028 - val_acc: 0.7674\n",
            "Epoch 333/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2022 - val_acc: 0.7674\n",
            "Epoch 334/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2027 - val_acc: 0.7674\n",
            "Epoch 335/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2031 - val_acc: 0.7674\n",
            "Epoch 336/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2030 - val_acc: 0.7674\n",
            "Epoch 337/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2031 - val_acc: 0.7674\n",
            "Epoch 338/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2031 - val_acc: 0.7674\n",
            "Epoch 339/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2035 - val_acc: 0.7674\n",
            "Epoch 340/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2026 - val_acc: 0.7674\n",
            "Epoch 341/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2030 - val_acc: 0.7674\n",
            "Epoch 342/1000\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2031 - val_acc: 0.7674\n",
            "Epoch 343/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2029 - val_acc: 0.7674\n",
            "Epoch 344/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2028 - val_acc: 0.7674\n",
            "Epoch 345/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2032 - val_acc: 0.7674\n",
            "Epoch 346/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2028 - val_acc: 0.7674\n",
            "Epoch 347/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2029 - val_acc: 0.7674\n",
            "Epoch 348/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2031 - val_acc: 0.7674\n",
            "Epoch 349/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2032 - val_acc: 0.7674\n",
            "Epoch 350/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2031 - val_acc: 0.7674\n",
            "Epoch 351/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2035 - val_acc: 0.7674\n",
            "Epoch 352/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2040 - val_acc: 0.7674\n",
            "Epoch 353/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 354/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2038 - val_acc: 0.7674\n",
            "Epoch 355/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2032 - val_acc: 0.7674\n",
            "Epoch 356/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2033 - val_acc: 0.7674\n",
            "Epoch 357/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2027 - val_acc: 0.7674\n",
            "Epoch 358/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2033 - val_acc: 0.7674\n",
            "Epoch 359/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9763 - val_loss: 0.2033 - val_acc: 0.7674\n",
            "Epoch 360/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2032 - val_acc: 0.7674\n",
            "Epoch 361/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2038 - val_acc: 0.7674\n",
            "Epoch 362/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2033 - val_acc: 0.7674\n",
            "Epoch 363/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2036 - val_acc: 0.7674\n",
            "Epoch 364/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2037 - val_acc: 0.7674\n",
            "Epoch 365/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2043 - val_acc: 0.7674\n",
            "Epoch 366/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2042 - val_acc: 0.7674\n",
            "Epoch 367/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2040 - val_acc: 0.7674\n",
            "Epoch 368/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2039 - val_acc: 0.7674\n",
            "Epoch 369/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2034 - val_acc: 0.7674\n",
            "Epoch 370/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2033 - val_acc: 0.7674\n",
            "Epoch 371/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2041 - val_acc: 0.7674\n",
            "Epoch 372/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2043 - val_acc: 0.7674\n",
            "Epoch 373/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2044 - val_acc: 0.7674\n",
            "Epoch 374/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2036 - val_acc: 0.7674\n",
            "Epoch 375/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2040 - val_acc: 0.7674\n",
            "Epoch 376/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2040 - val_acc: 0.7674\n",
            "Epoch 377/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 378/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 379/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2044 - val_acc: 0.7674\n",
            "Epoch 380/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2049 - val_acc: 0.7674\n",
            "Epoch 381/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 382/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2044 - val_acc: 0.7674\n",
            "Epoch 383/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 384/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 385/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2045 - val_acc: 0.7674\n",
            "Epoch 386/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2047 - val_acc: 0.7674\n",
            "Epoch 387/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2049 - val_acc: 0.7674\n",
            "Epoch 388/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2050 - val_acc: 0.7674\n",
            "Epoch 389/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2049 - val_acc: 0.7674\n",
            "Epoch 390/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2049 - val_acc: 0.7674\n",
            "Epoch 391/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2051 - val_acc: 0.7674\n",
            "Epoch 392/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2048 - val_acc: 0.7674\n",
            "Epoch 393/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2053 - val_acc: 0.7674\n",
            "Epoch 394/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2056 - val_acc: 0.7674\n",
            "Epoch 395/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2053 - val_acc: 0.7674\n",
            "Epoch 396/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2046 - val_acc: 0.7674\n",
            "Epoch 397/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2050 - val_acc: 0.7674\n",
            "Epoch 398/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2051 - val_acc: 0.7674\n",
            "Epoch 399/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2055 - val_acc: 0.7674\n",
            "Epoch 400/1000\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2053 - val_acc: 0.7674\n",
            "Epoch 401/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2049 - val_acc: 0.7674\n",
            "Epoch 402/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2052 - val_acc: 0.7674\n",
            "Epoch 403/1000\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2058 - val_acc: 0.7674\n",
            "Epoch 404/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2059 - val_acc: 0.7674\n",
            "Epoch 405/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2070 - val_acc: 0.7674\n",
            "Epoch 406/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2071 - val_acc: 0.7674\n",
            "Epoch 407/1000\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2067 - val_acc: 0.7674\n",
            "Epoch 408/1000\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9763 - val_loss: 0.2073 - val_acc: 0.7674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYpy54d2t4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "3c3550e7-7e4c-4713-8970-3ff226f45d59"
      },
      "source": [
        "### 12. What does the plot generated by this code represent?\n",
        "###     The plot generated by this code represent the accuracy of the model evaluated by using train dataset and test dataset.\n",
        "\n",
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrcCZ8P2t4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "501e33e9-3c2c-4b4b-9761-c4d0a0cf4e01"
      },
      "source": [
        "### 13. Plot code for the model loss. You can refer to the plot code for model accuracy above.\n",
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "#plt.savefig('Loss.png',dpi=100) #to save the image\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KTWzuJM12t4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c0eb51-1165-4e8d-ea79-b3d0a3bbcf73"
      },
      "source": [
        "### 14. What is the purpose of evaluating the model on the test dataset?\n",
        "###     The purpose purpose of evaluating the model on the test dataset is to evaluate the performance of the model build.\n",
        "###     Also, this can help in detecting and preventing overfitting by providing an independent evaluation of the model's performance.\n",
        "\n",
        "#model.load_weights(model_loc+\"heart_disease_best_model.hdf5\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"loss:\", round(scores[0],2))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1657 - acc: 0.8242\n",
            "\n",
            "acc: 82.42%\n",
            "loss: 0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYy0CRt2t4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94abee85-1f56-4a57-fcd0-4327934229af"
      },
      "source": [
        "#Display detailed prediction\n",
        "pred = model.predict(x_test)\n",
        "y = np.round(pred).astype(\"int16\")\n",
        "idx = 0\n",
        "ps = 0\n",
        "fl = 0\n",
        "for x in pred:\n",
        "    if y_test[idx]==y[idx]:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\"Result: \\033[92mPass\")\n",
        "        ps = ps+1\n",
        "    else:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\" Result: \\033[91mFail\")\n",
        "        fl = fl+1\n",
        "    idx = idx + 1\n",
        "print(\"\\033[30mRight Prediction :\",ps, \"Wrong Prediction :\",fl)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "\u001b[30mNo: 1 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 2 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 3 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 4 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 5 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 6 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 7 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 8 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 9 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 10 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 11 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 12 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 13 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 14 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 15 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 16 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 17 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 18 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 19 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 20 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 21 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 22 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 23 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 24 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 25 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 26 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 27 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 28 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 29 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 30 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 31 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 32 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 33 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 34 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 35 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 36 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 37 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 38 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 39 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 40 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 41 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 42 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 43 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 44 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 45 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 46 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 47 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 48 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 49 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 50 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 51 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 52 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 53 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 54 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 55 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 56 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 57 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 58 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 59 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 60 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 61 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 62 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 63 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 64 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 65 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 66 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 67 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 68 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 69 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 70 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 71 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 72 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 73 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 74 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 75 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 76 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 77 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 78 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 79 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 80 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 81 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 82 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 83 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 84 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 85 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 86 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 87 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 88 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 89 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 90 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 91 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mRight Prediction : 75 Wrong Prediction : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHQBXNX5aYcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "4c8b299b-3242-4249-cdf8-652f2af6e8ed"
      },
      "source": [
        "### 15. What is Confusion Matrix and why you need it? Explain TP, FP, FN, TN.\n",
        "###   Confusion matrix is a table that is often used to evaluate the performance of a classification model.\n",
        "###   - True Positive (TP): This represents the cases where the model correctly predicted the positive class (e.g., presence of a condition) when the actual class was indeed positive.\n",
        "###   - False Positive (FP): Also known as Type I error, this represents the cases where the model incorrectly predicted the positive class when the actual class was negative.\n",
        "###   - False Negative (FN): Also known as Type II error, this represents the cases where the model incorrectly predicted the negative class when the actual class was positive.\n",
        "###                           It's a case of the model failing to detect something that is actually present.\n",
        "###   - True Negative (TN): This represents the cases where the model correctly predicted the negative class (e.g., absence of a condition) when the actual class was indeed negative.\n",
        "\n",
        "### 16. Explain the classification report produce.\n",
        "\n",
        "y_pred = y\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "#cm = confusion_matrix(y_true, y_pred, labels=labels.astype('int'))\n",
        "f, ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidths=1.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.78      0.80        41\n",
            "           1       0.83      0.86      0.84        50\n",
            "\n",
            "    accuracy                           0.82        91\n",
            "   macro avg       0.82      0.82      0.82        91\n",
            "weighted avg       0.82      0.82      0.82        91\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The overall accuracy for this model is 82%.\n",
        "<br>\n",
        "The macro average is 0.82, which is the average of precision, recall and f1 score calculated independently for each class.\n",
        "<br>\n",
        "The weighted average is 0.82, which is the average of precision, recall and f1 score weighted by support for each class.\n",
        "- For Class 0:<br>\n",
        "  -- The precision value is 0.82, which mean there are 82% of instances which predicted as class 0 are in class 0 in actual.<br>\n",
        "  -- The recall value is 0.78, which mean that the model are correctly identify 78% of all actual class 0 instances.<br>\n",
        "  -- The f1 score is 0.80, which is the harmonic mean of precision and recall value for class 0.<br>\n",
        "  -- Support value for class 0 is 41, which mean there are 41 instances in class 0.<br>\n",
        "  <br>\n",
        "- For Class 1:<br>\n",
        "  -- The precision value is 0.83, which mean there are 83% of instances which predicted as class 1 are in class 1 in actual.<br>\n",
        "  -- The recall value is 0.86, which mean that the model are correctly identify 86% of all actual class 1 instances.<br>\n",
        "  -- The f1 score is 0.84, which is the harmonic mean of precision and recall value for class 1.<br>\n",
        "  -- Support value for class 1 is 50, which mean there are 50 instances in class 50.<br>"
      ],
      "metadata": {
        "id": "SDXpWKlz3i3p"
      }
    }
  ]
}
